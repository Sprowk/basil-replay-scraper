name: Daily BASIL Scrape and Commit

on:
  # Schedule the workflow to run automatically
  schedule:
    - cron: '0 8,20 * * *'

  # Allow manual triggering from the Actions tab in GitHub
  workflow_dispatch:

jobs:
  scrape_and_commit:
    runs-on: ubuntu-latest

    # Permissions needed to commit back to the repo
    permissions:
      contents: write

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Python dependencies
        run: pip install -r requirements.txt

      - name: Set up Chrome and ChromeDriver
        uses: browser-actions/setup-chrome@latest

      - name: Run Scraper Task
        run: python -c "import main; main.run_automated_task(download=False)"
        env:
          PYTHONUNBUFFERED: 1

      - name: Commit updated data files
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Automated update: Scrape results for ${{ env.DATE }}"
          file_pattern: "basil_ladder_games.csv daily_scrape.log"
          commit_user_name: GitHub Actions Bot
          commit_user_email: actions@github.com
        env:
          DATE: ${{ steps.date.outputs.date }}

      - id: date
        run: echo "::set-output name=date::$(date '+%Y-%m-%d %H:%M:%S')"
