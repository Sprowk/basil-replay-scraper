name: Daily BASIL Scrape and Commit

on:
  # Schedule the workflow to run automatically
  schedule:
    - cron: '0 8,20 * * *' # Runs at 08:00 and 20:00 UTC daily

  # Allow manual triggering from the Actions tab in GitHub
  workflow_dispatch:

jobs:
  scrape_and_commit:
    runs-on: ubuntu-latest

    # Permissions needed to commit back to the repo
    permissions:
      contents: write

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Python dependencies
        run: pip install -r requirements.txt

      - name: Set up Chrome and ChromeDriver
        uses: browser-actions/setup-chrome@latest

      - name: Run Scraper Task
        run: python -c "import main; main.run_automated_task(download=False)"
        env:
          PYTHONUNBUFFERED: 1 # For seeing logs in real-time

      - name: Get current date and time
        id: date # Give the step an ID to reference its outputs
        run: echo "DATE=$(date '+%Y-%m-%d %H:%M:%S')" >> $GITHUB_OUTPUT

      - name: Commit updated data files
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          # Directly use the output from the 'date' step
          commit_message: "Automated update: Scrape results for ${{ steps.date.outputs.DATE }}"
          file_pattern: "basil_ladder_games.csv daily_scrape.log" # Ensure these files actually change
          commit_user_name: GitHub Actions Bot
          commit_user_email: actions@github.com